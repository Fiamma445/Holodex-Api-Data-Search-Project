# Troubleshooting & Vibe Coding Log 

이 문서는 HoloProject 개발 과정에서 발생한 핵심 문제를 **SCQA** 프레임워크로 분석한 기록입니다.

데이터 분석가로서 설계한 **핵심 데이터 파이프라인(SQL/Python)**의 한계를 어떻게 돌파했는지, 그리고 본연의 직무 영역이 아닌 **프론트엔드 및 백엔드 인프라 배포** 영역을 **Vibe Coding**을 통해 어떻게 완수하여 독립적인 서비스로 확장시켰는지 증명합니다.

---

## Core Competency: Data Engineering 한계 돌파 
### Issue 1: Holodex 비정형 데이터 정규화 및 RDBMS 스키마 충돌

### Situation
YouTube 자체 검색이나 기존 Holodex 사이트의 기본 웹 인터페이스만으로는 '특정 연도의 월별 콜라보레이션 빈도', '특정 멤버 간의 합방 교차 필터링', '노이즈(쇼츠, 공지)가 제거된 순수 게임/노래 콘텐츠 비중' 등 세밀하고 다차원적인 복합 검색이 불가능한 구조적 한계가 존재했습니다.

### Complication
이러한 한계를 극복하기 위해 전 세계 1위 버튜버 아카이브인 **Holodex API**를 직접 연결하여 전 멤버의 Raw Data를 수급하고 독자적인 분석 파이프라인을 구축하고자 했습니다. 그러나, 버튜버 컨텐츠 특성상 합방 빈도가 잦아 단일 영상 데이터에 수많은 채널 데이터 배열(`mentions`)이 가변적인 JSON 형태로 중첩되어 들어왔습니다. 이를 기존 RDBMS의 엄격한 컬럼 스키마로 풀어내려면 불필요한 1:N 조인 테이블이 양산되고 쿼리 퍼포먼스가 급락하는 설계상의 모순이 발생했습니다.

### Question
> “어떻게 하면 RDBMS의 ACID 특성을 유지하면서 비정형 데이터를 마이그레이션 없이 쿼리하여 다차원 통계를 도출할 수 있는가?”

### Answer: 하이브리드 스키마 설계 및 파싱
데이터 분석가 관점에서, 핵심 컬럼만 `videos` 테이블로 구성하고 변동성이 큰 타겟 데이터는 직렬화된 채로 `json_data` 컬럼에 통째로 적재하는 하이브리드 설계를 확립했습니다. 
**SQLite JSON1 Extension**을 활용하여 SQL 단에서 `json_extract()` 함수로 필요한 요소만 조건부 탐색하는 메커니즘을 구상했습니다. 이 덕분에 도메인 지식(Holodex API 스펙)이 갑작스럽게 변경되더라도 DB 스키마 마이그레이션 공수 없이 즉각적인 쿼리 파싱과 인사이트 도출이 가능해졌습니다.

---

## Extended Capability: Vibe Coding
### Issue 2: 서버리스 인프라 병목 해결 (Railway & Cloudflare)

### Situation
데이터 파이프라인 완료 후, 추출된 인사이트를 실제 유저에게 서비스하기 위해 **Railway**와 **Cloudflare** 환경에 배포했습니다. 바닐라 JS 프론트엔드와 FastAPI 백엔드는 Vibe Coding을 통해 구현된 상태였습니다.

### Complication
실제 배포 도메인(`holo-search.xyz`) 접속 시 심각한 로딩 지연 현상(Slow TTFB & FCP)이 발생했습니다. 분석 전문성이 아닌 웹 인프라/프론트엔드 영역의 문제였습니다.
1. **Serverless Cold Start**: Railway의 절전 모드 특성상 초기 서버 구동에 3~5초 대기.
2. **Frontend Waterfall Loading**: 절차지향적으로 짜여진 JS 코드가 순차적으로 API를 호출하느라 I/O 대기 누적.

### Question
> “Vibe Coding을 활용하여 백엔드 캐시 제어와 프론트엔드 비동기 렌더링을 최적화하고 로딩 속도를 극복할 수 있는가?”

### Answer: Vibe Coding 기반 풀스택 튜닝

**1. Backend Proxy Caching**
Vibe Coding 세션을 통해 어플리케이션 코드를 뒤엎지 않고 Cloudflare의 Edge Cache를 활용하는 아키텍처를 도출했습니다. FastAPI 서버 라우터에 `Cache-Control` 헤더를 주입해, 정적 리소스 서빙 시 Railway 컨테이너를 타지 않고 Cloudflare 엣지단에서 즉시 반환되도록 구조를 바꿨습니다. TTFB가 수 밀리초(ms) 단위로 단축되었습니다.

```python
# Vibe Coding을 통해 즉시 도출된 Edge Caching 정책 라우팅
@app.get("/")
async def root():
    headers = {"Cache-Control": "public, max-age=3600, stale-while-revalidate=86400"}
    return FileResponse('public/index.html', headers=headers)
```

**2. Frontend 비동기 렌더링 병렬화**
순차적으로 돌던 기존 바닐라 JS 코드를 프롬프트 지시를 통해 모듈화하고, 다중 API Fetch 로직을 `Promise.all` 기반의 병렬 레이어로 리팩토링했습니다. 이를 통해 상용 서비스 환경의 렌더링 퍼포먼스를 개선했습니다.

---

### Issue 3: 과도한 채널 데이터 렌더링 리소스 낭비 및 UX 저하 (탤런트 동기화)

### Situation
초기 아키텍처는 유저가 대시보드 접속 시 DB에 적재된 수십 명의 전체 홀로라이브 멤버 데이터를 한 번에 모두 불러와 시각화하도록 설계되었습니다.

### Complication
수십 개의 채널 데이터를 전부 로딩하여 화면에 뿌려주는 방식은 불필요한 네트워크 및 브라우저 메모리 리소스를 낭비했습니다. 또한, 유저 입장에서는 본인이 관심 없는 멤버의 통계까지 무조건 봐야 하므로 탐색 직관성이 떨어지고 뷰포트가 과도하게 길어지는 등 기본적인 UX(사용자 경험)가 극심하게 저하되는 이슈가 있었습니다.

### Question
> “수십 개의 채널 데이터를 전부 보여주는 비효율을 제거하고, 본인이 즐겨찾기처럼 원하는 채널 통계만 커스텀하여 동기화할 수 있는가?”

### Answer: YouTube 검색 API 및 LocalStorage 커스텀 동기화 아키텍처
데이터 수집과는 별건으로, 프론트엔드에 **'탤런트 관리 모달'**을 구현하여 유저 맞춤형 '즐겨찾기' 구조를 정립했습니다. 
Vibe Coding을 통해 YouTube Data API를 연동하여 사용자가 원하는 채널만 동적으로 검색하고 추가/삭제할 수 있게 했으며, 완성된 타겟 리스트를 브라우저의 `LocalStorage`에 실시간으로 동기화합니다. 결과적으로 유저는 본인이 픽업한 소수의 채널 데이터만 API로 요청하여 화면에 띄우게 되었고, 서비스 초기 설정 시 발생하던 리소스 병목을 궁극적으로 차단함과 동시에 완벽한 커스텀 대시보드 뷰를 완성했습니다.

---

### Issue 4: AI 기반 TDD 파이프라인 및 에이전트 워크플로우 시스템화

### Situation
Vibe Coding을 통해 다차원 데이터 탐색 대시보드 아키텍처를 구성했으나, 대화형 프롬프팅만으로는 프로젝트 규모 확장에 따른 사이드 이펙트와 코드 품질 저하를 제어하기 어려웠습니다.

### Complication
개발자가 AI의 코드를 일일이 검증하고 수동으로 테스트하는 방식은 본업인 데이터 분석 리소스 투입을 저해했습니다. AI를 1회성 코드 생성 도구가 아닌, 정해진 규약과 테스트 수트에 따라 동작하는 시스템 단위로 제어할 필요성이 발생했습니다.

### Question
> “어떻게 하면 AI가 짜는 코드를 방임하지 않고, TDD 및 리뷰 파이프라인을 구축하여 에이전트의 작업 퀄리티를 통제할 수 있는가?”

### Answer: 커스텀 Workflow & Skills 구축
Vibe Coding의 퀄리티 컨트롤을 위해, 프로젝트 루트에 `.agent/workflows`와 `.agent/skills` 디렉터리를 구축하여 AI 전용 파이프라인을 설계했습니다. 
에이전트에게 코드를 짜게 만들기 전, 실패하는 테스트를 작성(RED)하고, 통과하는 최소 로직을 구현(GREEN)한 뒤, 리팩토링(IMPROVE)하는 **TDD 사이클을 강제하도록 시스템 프롬프팅을 구조화**했습니다. 이로써 AI가 작성한 프론트/백엔드 로직의 안정성을 확보했고, 배포 로직(`/deploy`)까지 명령어 기반으로 자동화하여 에이전트 통제 역량을 시스템 단위로 증명했습니다.
